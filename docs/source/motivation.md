# Why Benchmarking? 

A robust _benchmarking strategy_ for AI involves a systematic approach to
discovering, mapping, evaluating, and comparing AI models, algorithms, and
systems against emerging industry standards and research developments. This kind
on initiative aims to gain insights into AI technologies' performance,
efficiency, and effectiveness, identifying areas for improvement.
By implementing such strategic initiative, organizations can better understand
and enhance their AI technologies' performance across diverse and evolving
hardware environments.

## Motivation of benchmarking

- ***Fair comparisons***: Comparing AI assets and results across research papers
  and techniques
- ***Insight and Improvement***: Benchmarking activities provide valuable insights,
  driving improvements and informed decision-making to enhance AI system
performance and competitiveness.
- ***Target Audience***: AI practitioners and researchers aiming to understand
  their AI assets' behavior across diverse hardware resources.

## Relevance

- ***Pervasive AI***: As AI becomes more prevalent across various domains,
  understanding AI tools and algorithms' behavior on different computing
resources is crucial.  Characterization: Benchmarking characterizes how AI
algorithms perform across various hardware platforms and configurations,
offering a comprehensive understanding of their behavior.
- ***Complexity***: The effort is complicated by AI assets' variability in
  behavior based on numerous hyperparameters and performance differences on
heterogeneous hardware devices.
- ***AutoML***: Using AI itself to build and train ML models; the datasets
  obtained through benchmarking can be used used to guide the creation of new
models

## Challenges

- ***Hardware Spectrum***: AI applications now run across a wide range of
  hardware, from cloud and high-performance computing (HPC) resources to
embedded and low-power systems.
- ***Device Diversification***: The increasing capacity and performance of
  embedded devices enable them to perform sophisticated AI tasks, including new
applications in computer vision and speech recognition.
- ***Training with Open-Source Data***: AI model training, especially for tasks
  like computer vision and speech recognition, relies on machine learning
algorithms and extensive open-source datasets created by researchers.
- ***Standardisation Issues***: lack of standardised and easy benchmarking does
  not allow understanding when AI algorithms actually work.



